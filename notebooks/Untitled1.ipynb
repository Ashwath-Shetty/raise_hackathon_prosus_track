{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9320bf20-61d4-4425-bb03-270c4acd280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import httpx\n",
    "import json\n",
    "import os\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780fe9c5-fb61-4a09-9405-52c79104ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3-70b-8192\" # \"llama-3.3-70b-versatile\" #\n",
    "response_format={\"type\": \"json_object\"}\n",
    "seed = 42\n",
    "temperature=0\n",
    "top_p = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81d6b2-0bec-461a-97ca-3d18b7af74cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "from typing import Dict, List, Optional, Type\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Configuration\n",
    "# GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")  # Set your Groq API key\n",
    "\n",
    "SERP_API_KEY = \n",
    "\n",
    "cert = \"/Users/shettyra/Downloads/ZscalerRootCerts_2/ZscalerRootCertificate-2048-SHA256.crt\" \n",
    "# http_client = httpx.Client(verify=False)\n",
    "http_client=httpx.Client(verify=cert)\n",
    "# client = Groq(api_key=,http_client=http_client)\n",
    "\n",
    "# Data Models\n",
    "@dataclass\n",
    "class Restaurant:\n",
    "    name: str\n",
    "    address: str\n",
    "    rating: float\n",
    "    cuisine_type: str\n",
    "    phone: str = \"\"\n",
    "\n",
    "@dataclass\n",
    "class MenuItem:\n",
    "    name: str\n",
    "    price: float\n",
    "    description: str\n",
    "    category: str\n",
    "\n",
    "@dataclass\n",
    "class CartItem:\n",
    "    item: MenuItem\n",
    "    quantity: int\n",
    "\n",
    "@dataclass\n",
    "class UserProfile:\n",
    "    user_id: str\n",
    "    preferred_cuisines: List[str]\n",
    "    favorite_restaurants: List[str]\n",
    "    order_history: List[dict]\n",
    "    location: str = \"\"\n",
    "\n",
    "# Knowledge Graph (Simple JSON storage)\n",
    "class KnowledgeGraph:\n",
    "    def __init__(self):\n",
    "        self.users = {}\n",
    "        self.restaurants = {}\n",
    "        self.orders = {}\n",
    "    \n",
    "    def add_user(self, user_profile: UserProfile):\n",
    "        self.users[user_profile.user_id] = asdict(user_profile)\n",
    "    \n",
    "    def get_user(self, user_id: str) -> Optional[UserProfile]:\n",
    "        if user_id in self.users:\n",
    "            data = self.users[user_id]\n",
    "            return UserProfile(**data)\n",
    "        return None\n",
    "    \n",
    "    def update_user_preferences(self, user_id: str, cuisine: str, restaurant: str):\n",
    "        if user_id not in self.users:\n",
    "            self.users[user_id] = asdict(UserProfile(user_id, [], [], []))\n",
    "        \n",
    "        user_data = self.users[user_id]\n",
    "        if cuisine not in user_data['preferred_cuisines']:\n",
    "            user_data['preferred_cuisines'].append(cuisine)\n",
    "        if restaurant not in user_data['favorite_restaurants']:\n",
    "            user_data['favorite_restaurants'].append(restaurant)\n",
    "\n",
    "\n",
    "# tools\n",
    "\n",
    "class LocationNormalizerInput(BaseModel):\n",
    "    user_message: str = Field(description=\"User's raw location message\")\n",
    "\n",
    "class LocationNormalizerTool(BaseTool):\n",
    "    name: str = \"location_normalizer\"\n",
    "    description: str = \"Convert user location input into a clean location string suitable for search\"\n",
    "    args_schema: Type[BaseModel] = LocationNormalizerInput\n",
    "\n",
    "    def _run(self, user_message: str) -> dict:\n",
    "        prompt = f\"\"\"\n",
    "    You are a helpful assistant that takes messy or informal location input and converts it into a clean, globally recognized location string.\n",
    "    \n",
    "    Respond ONLY with JSON in this format:\n",
    "    {{\n",
    "        \"location\": \"Koramangala, Bengaluru, India\",\n",
    "        \"ll\": \"12.9352,77.6245\"\n",
    "    }}\n",
    "    \n",
    "    Input: \"{user_message}\"\n",
    "    \"\"\"\n",
    "        llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name=\"llama3-8b-8192\", temperature=0.2,http_client=http_client)\n",
    "        response = llm.invoke(prompt)\n",
    "    \n",
    "        # ✅ Convert to plain string if needed\n",
    "        if hasattr(response, \"content\"):\n",
    "            response = response.content\n",
    "    \n",
    "        try:\n",
    "            json_str = re.search(r'\\{.*\\}', response, re.DOTALL).group()\n",
    "            return json.loads(json_str)\n",
    "        except Exception as e:\n",
    "            print(f\"[LLM LocationNormalizer Error]: {e}\")\n",
    "            return {\"location\": user_message.title()}\n",
    "\n",
    "    def _arun(self, user_message: str):\n",
    "        raise NotImplementedError(\"Async not supported\")\n",
    "\n",
    "\n",
    "\n",
    "class RestaurantSearchInput(BaseModel):\n",
    "    location: str = Field(description=\"User's location or lat,long\")\n",
    "    food_type: str = Field(default=\"\", description=\"Type of food (optional)\")\n",
    "\n",
    "class RestaurantSearchTool(BaseTool):\n",
    "    name: str = \"restaurant_search\"\n",
    "    description: str = \"Search for restaurants based on location and food type\"\n",
    "    args_schema: Type[BaseModel] = RestaurantSearchInput\n",
    "\n",
    "    def _run(self, location: str, food_type: str = \"\") -> str:\n",
    "        try:\n",
    "            mock_restaurants = self._generate_restaurants(location, food_type)\n",
    "            if not mock_restaurants:\n",
    "                return f\"❌ No '{food_type}' restaurants found near {location}.\"\n",
    "\n",
    "            result = f\"🍽️ Top {min(3, len(mock_restaurants))} restaurants found for '{food_type}' in {location}:\\n\\n\"\n",
    "            for i, r in enumerate(mock_restaurants[:3], 1):\n",
    "                stars = \"⭐\" * int(r.rating) if r.rating > 0 else \"No rating\"\n",
    "                result += f\"{i}. **{r.name}**\\n\"\n",
    "                result += f\"   📍 {r.address}\\n\"\n",
    "                result += f\"   🍴 {r.cuisine_type}\\n\"\n",
    "                result += f\"   {stars} ({r.rating}/5)\\n\\n\"\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[RestaurantSearch Error]: {e}\")\n",
    "            return f\"⚠️ Error searching for restaurants near {location}.\"\n",
    "\n",
    "    def _generate_restaurants(self, location: str, food_type: str = \"\") -> List[Restaurant]:\n",
    "        try:\n",
    "            # Force usage of location string; lat/long often fails outside the US\n",
    "            query = f\"{food_type} restaurants in {location}\"\n",
    "            params = {\n",
    "                \"engine\": \"google_maps\",\n",
    "                \"type\": \"search\",\n",
    "                \"q\": query,\n",
    "                \"location\": location,\n",
    "                \"api_key\": SERP_API_KEY\n",
    "            }\n",
    "    \n",
    "            response = requests.get(\"https://serpapi.com/search\", params=params)\n",
    "            data = response.json()\n",
    "    \n",
    "            results = []\n",
    "            for place in data.get(\"local_results\", [])[:5]:\n",
    "                results.append(\n",
    "                    Restaurant(\n",
    "                        name=place.get(\"title\", \"Unknown\"),\n",
    "                        address=place.get(\"address\", \"Unknown\"),\n",
    "                        rating=float(place.get(\"rating\", 0.0)),\n",
    "                        cuisine_type=food_type,\n",
    "                        phone=place.get(\"phone\", \"\")\n",
    "                    )\n",
    "                )\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(\"SerpAPI error:\", e)\n",
    "            return []\n",
    "\n",
    "\n",
    "    def _arun(self, location: str, food_type: str = \"\"):\n",
    "        raise NotImplementedError(\"Async not implemented\")\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "class MenuInput(BaseModel):\n",
    "    restaurant_name: str = Field(description=\"Name of the restaurant\")\n",
    "    cuisine_type: str = Field(description=\"Type of cuisine the restaurant serves\")\n",
    "\n",
    "class MenuTool(BaseTool):\n",
    "    name: str = \"get_menu\"\n",
    "    description: str = \"Get menu for a specific restaurant based on its cuisine type\"\n",
    "    args_schema: Type[BaseModel] = MenuInput\n",
    "\n",
    "    def _run(self, restaurant_name: str, cuisine_type: str) -> str:\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "                        You're an expert menu designer. Create a realistic and appealing menu for a restaurant named \"{restaurant_name}\".\n",
    "                        Cuisine: {cuisine_type}\n",
    "                        Generate 4–6 menu items. For each item, include:\n",
    "                        \n",
    "                        - Dish name\n",
    "                        - Short 1-line description\n",
    "                        - Price (in USD, $5–$20)\n",
    "                        - Category (e.g., Appetizer, Main Course, Dessert)\n",
    "                        \n",
    "                        Respond in this format only:\n",
    "                        Dish Name | Price | Category | Description\n",
    "                        \n",
    "                        Example:\n",
    "                        Margherita Pizza | $12.99 | Main Course | Classic tomato, mozzarella, and basil on sourdough crust.\n",
    "                        \"\"\"\n",
    "\n",
    "            llm = ChatGroq(\n",
    "                temperature=0.3,\n",
    "                groq_api_key=GROQ_API_KEY,\n",
    "                model_name=\"llama3-8b-8192\",\n",
    "                http_client=http_client\n",
    "            )\n",
    "\n",
    "            result = llm.invoke(prompt)\n",
    "            raw_structured = result.content.strip()\n",
    "            formatted = self._format_llm_menu(raw_structured, restaurant_name)\n",
    "            return formatted, raw_structured\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[MenuTool LLM Error]: {e}\")\n",
    "            return \"Sorry, I couldn't generate the menu at the moment. Please try again later.\"\n",
    "\n",
    "\n",
    "    def _format_llm_menu(self, raw_output: str, restaurant_name: str) -> str:\n",
    "        lines = [line.strip() for line in raw_output.strip().split(\"\\n\") if line.strip()]\n",
    "        result = f\"🍽️ Menu for {restaurant_name}:\\n\\n\"\n",
    "    \n",
    "        categories = {}\n",
    "        for line in lines:\n",
    "            # Skip header or lines that don't have exactly 4 parts\n",
    "            if line.lower().startswith(\"dish name\") or line.count(\"|\") != 3:\n",
    "                continue\n",
    "            try:\n",
    "                name, price, category, desc = [part.strip() for part in line.split(\"|\")]\n",
    "                if category not in categories:\n",
    "                    categories[category] = []\n",
    "                categories[category].append((name, price, desc))\n",
    "            except Exception as e:\n",
    "                print(\"[Menu Parse Error]:\", e, \"Line:\", line)\n",
    "    \n",
    "        for cat, items in categories.items():\n",
    "            result += f\"📂 {cat}\\n\"\n",
    "            for name, price, desc in items:\n",
    "                result += f\"   • {name} - {price}\\n\"\n",
    "                result += f\"     {desc}\\n\\n\"\n",
    "    \n",
    "        result += \"💡 To add items to your cart, say something like:\\n\"\n",
    "        result += \"   'Add 2 Margherita Pizza' or 'I want the Caesar Salad'\"\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CART_EXTRACTION_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent assistant that extracts food order items from customer messages.\n",
    "\n",
    "Given a menu and a user message, return a structured JSON list of the items the user wants to add to their cart. Each item should include the dish name and quantity.\n",
    "\n",
    "### Menu:\n",
    "{menu}\n",
    "\n",
    "### User message:\n",
    "{message}\n",
    "\n",
    "### JSON Output format:\n",
    "[\n",
    "  {{\n",
    "    \"item\": \"<dish name from the menu>\",\n",
    "    \"quantity\": <integer>\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Only include items from the menu. If none match, return an empty list.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # normalize spaces\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08857397-1534-4a3f-9fa8-53201a287a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeGraph:\n",
    "    def __init__(self):\n",
    "        self.users = {}\n",
    "        self.restaurants = {}\n",
    "        self.orders = {}\n",
    "    \n",
    "    def add_user(self, user_profile: UserProfile):\n",
    "        self.users[user_profile.user_id] = asdict(user_profile)\n",
    "    \n",
    "    def get_user(self, user_id: str) -> Optional[UserProfile]:\n",
    "        if user_id in self.users:\n",
    "            data = self.users[user_id]\n",
    "            return UserProfile(**data)\n",
    "        return None\n",
    "    \n",
    "    def update_user_preferences(self, user_id: str, cuisine: str, restaurant: str):\n",
    "        if user_id not in self.users:\n",
    "            self.users[user_id] = asdict(UserProfile(user_id, [], [], []))\n",
    "        \n",
    "        user_data = self.users[user_id]\n",
    "        if cuisine not in user_data['preferred_cuisines']:\n",
    "            user_data['preferred_cuisines'].append(cuisine)\n",
    "        if restaurant not in user_data['favorite_restaurants']:\n",
    "            user_data['favorite_restaurants'].append(restaurant)\n",
    "\n",
    "    def debug_view(self):\n",
    "        print(\"\\n=== KNOWLEDGE GRAPH STATE ===\")\n",
    "        print(\"📌 Users:\")\n",
    "        pprint.pprint(self.users)\n",
    "        print(\"\\n📌 Restaurants:\")\n",
    "        pprint.pprint(self.restaurants)\n",
    "        print(\"\\n📌 Orders:\")\n",
    "        pprint.pprint(self.orders)\n",
    "        print(\"=============================\\n\")\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "# Food Ordering Agent\n",
    "class FoodOrderingAgent:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGroq(\n",
    "            temperature=0.1,\n",
    "            groq_api_key=GROQ_API_KEY,\n",
    "            model_name=\"llama3-8b-8192\",\n",
    "            http_client=http_client\n",
    "        )\n",
    "        \n",
    "        self.knowledge_graph = KnowledgeGraph()\n",
    "        self.current_user_id = \"user_001\"  # Simple user ID for demo\n",
    "        self.current_location = \"\"\n",
    "        self.current_cuisine = \"\"\n",
    "        self.selected_restaurant = \"\"\n",
    "        self.cart = []\n",
    "        self.conversation_state = \"greeting\"\n",
    "        self.raw_menu_text = \"\"\n",
    "        self.structured_menu_text = \"\"\n",
    "\n",
    "        \n",
    "        # Memory\n",
    "        self.memory = ConversationBufferWindowMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            k=10,\n",
    "            return_messages=True\n",
    "        )\n",
    "        \n",
    "        # Tools\n",
    "        self.tools = [\n",
    "            LocationNormalizerTool(),\n",
    "            RestaurantSearchTool(),\n",
    "            MenuTool()\n",
    "        ]\n",
    "        \n",
    "        # Agent prompt\n",
    "        self.agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        You are a helpful food ordering assistant. Follow these stages:\n",
    "        \n",
    "        1. GREETING: Welcome the user warmly\n",
    "        2. LOCATION: Ask for user's location\n",
    "        3. FOOD_PREFERENCE: Ask what type of food they want\n",
    "        4. RESTAURANT_SEARCH: Use restaurant_search tool to find restaurants\n",
    "        5. RESTAURANT_SELECTION: Help user select a restaurant\n",
    "        6. MENU_DISPLAY: Use get_menu tool to show menu\n",
    "        7. ORDER_TAKING: Help user add items to cart\n",
    "        8. ORDER_CONFIRMATION: Confirm the order\n",
    "        9. ORDER_PROCESSING: Process the order\n",
    "        \n",
    "        Current conversation state: {state}\n",
    "        User location: {location}\n",
    "        Selected restaurant: {restaurant}\n",
    "        Current cart: {cart}\n",
    "        \n",
    "        Tools available: {tools}\n",
    "        \n",
    "        Previous conversation:\n",
    "        {chat_history}\n",
    "        \n",
    "        Human: {input}\n",
    "        \n",
    "        Remember to:\n",
    "        - Be friendly and helpful\n",
    "        - Ask one question at a time\n",
    "        - Use tools when needed\n",
    "        - Keep track of the conversation flow\n",
    "        - Confirm details before proceeding\n",
    "        \n",
    "        Assistant:\n",
    "        \"\"\")\n",
    "\n",
    "    def parse_llm_menu(self, menu_text: str) -> List[MenuItem]:\n",
    "        \"\"\"Parse LLM-formatted menu into structured MenuItem objects\"\"\"\n",
    "        items = []\n",
    "        lines = [line.strip() for line in menu_text.split(\"\\n\") if line.strip()]\n",
    "        for line in lines:\n",
    "            if line.lower().startswith(\"dish name\") or line.count(\"|\") != 3:\n",
    "                continue\n",
    "            try:\n",
    "                # name, price, category, desc = [part.strip() for part in line.split(\"|\")]\n",
    "                raw_name, price, category, desc = [part.strip() for part in line.split(\"|\")]\n",
    "                # Remove numbering prefix like \"1. \" from dish name\n",
    "                # name = re.sub(r\"^\\d+\\.\\s*\", \"\", raw_name)\n",
    "                name = re.sub(r\"^[•\\-\\d\\. ]+\", \"\", raw_name)\n",
    "\n",
    "                \n",
    "                price_float = float(price.replace(\"$\", \"\").strip())\n",
    "                items.append(MenuItem(name=name, price=price_float, description=desc, category=category))\n",
    "            except Exception as e:\n",
    "                print(f\"[Menu Parse Error]: {e} -- Line: {line}\")\n",
    "        return items\n",
    "\n",
    "    \n",
    "    def process_message(self, message: str) -> str:\n",
    "        \"\"\"Process user message and return response\"\"\"\n",
    "        try:\n",
    "            response = \"\"\n",
    "\n",
    "            if any(kw in message.lower() for kw in [\"cart\", \"show cart\", \"view cart\"]):\n",
    "                response = self.get_cart_summary()\n",
    "                # Log memory (optional)\n",
    "                self.memory.chat_memory.add_user_message(message)\n",
    "                self.memory.chat_memory.add_ai_message(response)\n",
    "                return response\n",
    "            \n",
    "            # Simple state machine logic\n",
    "            if self.conversation_state == \"greeting\":\n",
    "                response = \"Hello! Welcome to our food ordering service!  I'm here to help you find and order delicious food. What's your location so I can find restaurants near you?\"\n",
    "                self.conversation_state = \"location\"\n",
    "                \n",
    "            # elif self.conversation_state == \"location\":\n",
    "            #     self.current_location = message.strip()\n",
    "            #     response = f\"Great! I've set your location to {self.current_location}. What type of food are you craving today? (e.g., pizza, burgers, sushi, etc.)\"\n",
    "            #     self.conversation_state = \"food_preference\"\n",
    "\n",
    "            elif self.conversation_state == \"location\":\n",
    "                try:\n",
    "                    loc_tool = LocationNormalizerTool()\n",
    "                    norm = loc_tool._run(message.strip())\n",
    "                    self.current_location = norm.get(\"location\", message.strip().title())\n",
    "                    response = f\"Great! I've set your location to {self.current_location}. What type of food are you craving today? (e.g., pizza, burgers, sushi, etc.)\"\n",
    "                    self.conversation_state = \"food_preference\"\n",
    "                except Exception as e:\n",
    "                    print(\"Location normalization failed:\", e)\n",
    "                    print(\"Location normalization failed:\", e)\n",
    "                    self.current_location = message.strip().title()\n",
    "                    response = f\"Okay, I've set your location to **{self.current_location}**. Now tell me what you're craving!\"\n",
    "                    self.conversation_state = \"food_preference\"  # 👈 Advance state even in fallback\n",
    "                    # normalizer = LocationNormalizerTool()\n",
    "                #     result = normalizer._run(message)\n",
    "                #     self.current_location = result.get(\"location\", message.title())\n",
    "                #     response = f\"Great! I've set your location to **{self.current_location}**. What type of food are you craving today? (e.g., pizza, burgers, sushi, etc.)\"\n",
    "                #     self.conversation_state = \"food_preference\"\n",
    "                # except Exception as e:\n",
    "                #     print(\"Location normalization failed:\", e)\n",
    "                #     self.current_location = message.strip().title()\n",
    "                #     response = f\"Okay, I've set your location to **{self.current_location}**. Now tell me what you're craving!\"\n",
    "                #     self.conversation_state = \"food_preference\"\n",
    "\n",
    "                \n",
    "            elif self.conversation_state == \"food_preference\":\n",
    "                self.current_cuisine = message.strip()\n",
    "                # Use restaurant search tool\n",
    "                search_tool = RestaurantSearchTool()\n",
    "                restaurants = search_tool._run(self.current_location, self.current_cuisine)\n",
    "                response = f\"{restaurants}\\nWhich restaurant would you like to order from? Just tell me the name or number.\"\n",
    "                self.conversation_state = \"restaurant_selection\"\n",
    "                \n",
    "            elif self.conversation_state == \"restaurant_selection\":\n",
    "                # Parse restaurant selection\n",
    "                selection = message.strip().lower()\n",
    "\n",
    "                print(selection,self.current_cuisine)\n",
    "                \n",
    "                # Get the list of generated restaurants\n",
    "                search_tool = RestaurantSearchTool()\n",
    "                mock_restaurants = search_tool._generate_restaurants(self.current_location, self.current_cuisine)\n",
    "                \n",
    "                # Match selection to restaurant\n",
    "                selected_index = None\n",
    "                for i, restaurant in enumerate(mock_restaurants, 1):\n",
    "                    name = restaurant.name.lower()\n",
    "                \n",
    "                    if str(i) == selection:\n",
    "                        selected_index = i - 1\n",
    "                        break\n",
    "                    elif selection in name:  # 👈 allows partial match like \"chianti\"\n",
    "                        selected_index = i - 1\n",
    "                        break\n",
    "                # for i, restaurant in enumerate(mock_restaurants, 1):\n",
    "                #     if str(i) in selection or restaurant.name.lower() in selection:\n",
    "                #         selected_index = i - 1\n",
    "                #         break\n",
    "                \n",
    "                if selected_index is not None:\n",
    "                    self.selected_restaurant = mock_restaurants[selected_index].name\n",
    "                    cuisine_type = mock_restaurants[selected_index].cuisine_type\n",
    "                    \n",
    "                    # Get menu\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    menu_tool = MenuTool()\n",
    "                    # raw_menu = menu_tool._run(self.selected_restaurant, cuisine_type)\n",
    "                    # self.raw_menu_text = raw_menu  \n",
    "\n",
    "                    formatted_menu, structured_menu = menu_tool._run(self.selected_restaurant, cuisine_type)\n",
    "                    self.raw_menu_text = formatted_menu\n",
    "                    self.structured_menu_text = structured_menu  # 👈 save this for parsing later\n",
    "\n",
    "                    \n",
    "                    # menu = menu_tool._run(self.selected_restaurant, cuisine_type)\n",
    "                    response = f\"Excellent choice! Here's the menu for {self.selected_restaurant}:\\n\\n{formatted_menu}\\n\\nWhat would you like to add to your cart? You can say something like 'Add 2 Margherita Pizza' or 'I want the Caesar Salad'.\"\n",
    "                    self.conversation_state = \"ordering\"\n",
    "                else:\n",
    "                    response = \"I didn't catch that. Please select one of the restaurants listed above.\"\n",
    "                \n",
    "            \n",
    "            elif self.conversation_state == \"ordering\":\n",
    "                if any(k in message.lower() for k in [\"add\", \"want\", \"order\"]):\n",
    "                    # Call LLM to parse cart items\n",
    "                    cart_extractor_prompt = CART_EXTRACTION_PROMPT.format(\n",
    "                        menu=self.raw_menu_text,\n",
    "                        message=message\n",
    "                    )\n",
    "                    llm_response = self.llm.invoke(cart_extractor_prompt)\n",
    "                    raw_json_text = llm_response.content\n",
    "                    cleaned_json = re.search(r\"\\[.*\\]\", raw_json_text, re.DOTALL)\n",
    "                    if cleaned_json:\n",
    "                        raw_json_text = cleaned_json.group(0)\n",
    "\n",
    "                    try:\n",
    "                        extracted_items = json.loads(raw_json_text)\n",
    "                    except Exception as e:\n",
    "                        print(\"Failed to parse JSON:\", e)\n",
    "                        extracted_items = []\n",
    "\n",
    "                    print(\"LLM Extracted Cart JSON:\", llm_response)\n",
    "                    print(\"extracted_items\",extracted_items)\n",
    "\n",
    "                    \n",
    "                    # try:\n",
    "                    #     extracted_items = json.loads(llm_response)\n",
    "                    # except Exception as e:\n",
    "                    #     print(\"Failed to parse JSON:\", e)\n",
    "                    #     extracted_items = []\n",
    "            \n",
    "                    # menu_items = self.parse_llm_menu(self.raw_menu_text)\n",
    "                    menu_items = self.parse_llm_menu(self.structured_menu_text)\n",
    "                    print(\"Parsed Menu Items:\", [m.name for m in menu_items])\n",
    "\n",
    "\n",
    "                    # menu_lookup = {item.name.lower(): item for item in menu_items}\n",
    "                    menu_lookup = {normalize(item.name): item for item in menu_items}\n",
    "\n",
    "                    print(\"menu items, menu look up\", menu_items,menu_lookup)\n",
    "            \n",
    "                    added = []\n",
    "                    unmatched = []\n",
    "                    for entry in extracted_items:\n",
    "                        \n",
    "                        name = normalize(entry[\"item\"])\n",
    "                        matched = menu_lookup.get(name)\n",
    "                        quantity = entry.get(\"quantity\", 1)\n",
    "\n",
    "                        print(f\"User requested item: {entry['item']} — matched to: {matched.name if matched else 'None'}\")\n",
    "                        # print(f\"User requested item: {entry['item']} — matched to: {matched.name if matched else None}\")\n",
    "\n",
    "\n",
    "                        if not matched:\n",
    "                            close = get_close_matches(name, list(menu_lookup.keys()), n=1, cutoff=0.5)\n",
    "                            if close:\n",
    "                                matched = menu_lookup[close[0]]\n",
    "\n",
    "                        if matched:\n",
    "                            self.cart.append(CartItem(matched, quantity))\n",
    "                            added.append(f\"{quantity} x {matched.name}\")\n",
    "                        else:\n",
    "                            print(f\"Unmatched item: {entry['item']}\")\n",
    "                            unmatched.append(entry[\"item\"])\n",
    "                        \n",
    "                        # quantity = entry.get(\"quantity\", 1)\n",
    "                        # if name in menu_lookup:\n",
    "                        #     self.cart.append(CartItem(menu_lookup[name], quantity))\n",
    "                        #     added.append(f\"{quantity} x {menu_lookup[name].name}\")\n",
    "            \n",
    "                    \n",
    "\n",
    "                    if added:\n",
    "                        cart_summary = self.get_cart_summary()\n",
    "                        response = f\"🛒 Added to cart:\\n- \" + \"\\n- \".join(added) + f\"\\n\\n{cart_summary}\\n\\nWould you like to add more or checkout?\"\n",
    "                        if unmatched:\n",
    "                            response += \"\\n\\n🚫 The following items were not found on the menu and were **not** added to your cart:\\n- \" + \"\\n- \".join(unmatched)\n",
    "                        \n",
    "                        # response += f\"\\n\\n{cart_summary}\\n\\nWould you like to add more or checkout?\"\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        response = f\"🚫 None of those items were found on the menu. Here's the menu again:\\n\\n{self.raw_menu_text}\"\n",
    "            \n",
    "                # elif \"checkout\" in message.lower():\n",
    "                #     if self.cart:\n",
    "                #         cart_summary = self.get_cart_summary()\n",
    "                #         response = f\"🧾 Order Summary:\\n\\n{cart_summary}\\n\\nWould you like to confirm your order? (yes/no)\"\n",
    "                #         self.conversation_state = \"confirmation\"\n",
    "                #     else:\n",
    "                #         response = \"🛒 Your cart is empty. Add some items first!\"\n",
    "\n",
    "                elif any(k in message.lower() for k in [\"remove\", \"delete\"]):\n",
    "                    \n",
    "                    # Try to parse what to remove\n",
    "                    to_remove = re.findall(r\"\\d*\\s*\\w+\", message.lower())\n",
    "                    removed = []\n",
    "                    for entry in to_remove:\n",
    "                        parts = entry.strip().split()\n",
    "                        if len(parts) == 2:\n",
    "                            qty_text, item_text = parts\n",
    "                        else:\n",
    "                            qty_text = \"1\"\n",
    "                            item_text = parts[0]\n",
    "                        \n",
    "                        try:\n",
    "                            quantity = int(qty_text)\n",
    "                        except ValueError:\n",
    "                            quantity = 1\n",
    "                \n",
    "                        item_name = normalize(item_text)\n",
    "                        match_found = False\n",
    "                        for cart_item in self.cart:\n",
    "                            if normalize(cart_item.item.name) == item_name:\n",
    "                                if cart_item.quantity <= quantity:\n",
    "                                    self.cart.remove(cart_item)\n",
    "                                else:\n",
    "                                    cart_item.quantity -= quantity\n",
    "                                removed.append(f\"{quantity} x {cart_item.item.name}\")\n",
    "                                match_found = True\n",
    "                                break\n",
    "                        \n",
    "                        if not match_found:\n",
    "                            cart_lookup = {normalize(ci.item.name): ci for ci in self.cart}\n",
    "                            close = get_close_matches(item_name, list(cart_lookup.keys()), n=1, cutoff=0.6)\n",
    "                            \n",
    "                            if close:\n",
    "                                matched_cart_item = cart_lookup[close[0]]\n",
    "                                if matched_cart_item.quantity <= quantity:\n",
    "                                    self.cart.remove(matched_cart_item)\n",
    "                                else:\n",
    "                                    matched_cart_item.quantity -= quantity\n",
    "                                removed.append(f\"{quantity} x {matched_cart_item.item.name}\")\n",
    "                                match_found = True\n",
    "                            else:\n",
    "                                print(f\"No matching item found in cart for: {item_name}\")\n",
    "                    \n",
    "                    if removed:\n",
    "                        cart_summary = self.get_cart_summary()\n",
    "                        response = f\"🗑️ Removed from cart:\\n- \" + \"\\n- \".join(removed) + f\"\\n\\n{cart_summary}\\n\\nWould you like to add more or checkout?\"\n",
    "                    else:\n",
    "                        response = f\"⚠️ Couldn't find those items in your cart. Try using the item names as shown in the menu.\"\n",
    "\n",
    "\n",
    "            \n",
    "                elif \"checkout\" in message.lower() or \"done\" in message.lower():\n",
    "                    if self.cart:\n",
    "                        cart_summary = self.get_cart_summary()\n",
    "                        response = f\"Perfect! Here's your order summary:\\n\\n{cart_summary}\\n\\nWould you like to confirm this order? (yes/no)\"\n",
    "                        self.conversation_state = \"confirmation\"\n",
    "                    else:\n",
    "                        response = \"Your cart is empty. Please add some items first!\"\n",
    "                \n",
    "                    # else:\n",
    "                    #     response = \"I can help you add items to your cart. Try saying 'Add [item name]' or 'checkout' when you're ready.\"\n",
    "\n",
    "                    \n",
    "            elif self.conversation_state == \"confirmation\":\n",
    "                if \"yes\" in message.lower():\n",
    "                    order_id = self.process_order()\n",
    "                    response = f\"🎉 Order confirmed! Your order #{order_id} has been placed successfully.\\n\\nDelivery time: 30-45 minutes\\nRestaurant: {self.selected_restaurant}\\nTotal: ${self.get_total():.2f}\\n\\nThank you for your order! You'll receive updates via SMS.\"\n",
    "                    self.save_user_preferences()\n",
    "                    self.reset_conversation()\n",
    "                else:\n",
    "                    response = \"No problem! You can continue adding items or modify your order. What would you like to do?\"\n",
    "                    self.conversation_state = \"ordering\"\n",
    "\n",
    "            \n",
    "                # return response\n",
    "\n",
    "\n",
    "            \n",
    "            else:\n",
    "                response = \"I'm here to help you order food! Would you like to start a new order?\"\n",
    "                self.conversation_state = \"greeting\"\n",
    "            \n",
    "            # Add to memory\n",
    "            self.memory.chat_memory.add_user_message(message)\n",
    "            self.memory.chat_memory.add_ai_message(response)\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"I apologize, but I encountered an error: {str(e)}. Let's start over - what's your location?\"\n",
    "    \n",
    "    def get_cart_summary(self) -> str:\n",
    "        \"\"\"Get formatted cart summary\"\"\"\n",
    "        if not self.cart:\n",
    "            return \"Your cart is empty.\"\n",
    "        \n",
    "        summary = f\"🛒 Your Cart ({self.selected_restaurant}):\\n\"\n",
    "        total = 0\n",
    "        for cart_item in self.cart:\n",
    "            item_total = cart_item.item.price * cart_item.quantity\n",
    "            summary += f\"- {cart_item.quantity}x {cart_item.item.name}: ${item_total:.2f}\\n\"\n",
    "            total += item_total\n",
    "        \n",
    "        summary += f\"\\n💰 Total: ${total:.2f}\"\n",
    "        return summary\n",
    "    \n",
    "    def get_total(self) -> float:\n",
    "        \"\"\"Calculate total cart value\"\"\"\n",
    "        return sum(item.item.price * item.quantity for item in self.cart)\n",
    "    \n",
    "    def process_order(self) -> str:\n",
    "        \"\"\"Process the order\"\"\"\n",
    "        order_id = f\"ORD{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "        \n",
    "        # Save order to knowledge graph\n",
    "        order_data = {\n",
    "            \"order_id\": order_id,\n",
    "            \"user_id\": self.current_user_id,\n",
    "            \"restaurant\": self.selected_restaurant,\n",
    "            \"items\": [{\"name\": item.item.name, \"quantity\": item.quantity, \"price\": item.item.price} for item in self.cart],\n",
    "            \"total\": self.get_total(),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"location\": self.current_location\n",
    "        }\n",
    "        \n",
    "        self.knowledge_graph.orders[order_id] = order_data\n",
    "        print(f\"✅ Order added to Knowledge Graph: {order_id}\")\n",
    "        self.knowledge_graph.debug_view()\n",
    "        \n",
    "        return order_id\n",
    "    \n",
    "    def save_user_preferences(self):\n",
    "        \"\"\"Save user preferences to knowledge graph\"\"\"\n",
    "        if self.selected_restaurant:\n",
    "            # Get cuisine type from generated restaurants\n",
    "            search_tool = RestaurantSearchTool()\n",
    "            mock_restaurants = search_tool._generate_restaurants(self.current_location, self.current_cuisine)\n",
    "            current_restaurant = next((r for r in mock_restaurants if r.name == self.selected_restaurant), None)\n",
    "            \n",
    "            if current_restaurant:\n",
    "                self.knowledge_graph.update_user_preferences(\n",
    "                    self.current_user_id,\n",
    "                    current_restaurant.cuisine_type,\n",
    "                    self.selected_restaurant\n",
    "                )\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Reset for new conversation\"\"\"\n",
    "        self.conversation_state = \"greeting\"\n",
    "        self.current_location = \"\"\n",
    "        self.current_cuisine = \"\"\n",
    "        self.selected_restaurant = \"\"\n",
    "        self.cart = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a25019-84fd-42ea-a7eb-e7f55ca12560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def render_knowledge_graph(agent: FoodOrderingAgent) -> Image.Image:\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add user node\n",
    "    user_id = agent.current_user_id\n",
    "    G.add_node(user_id, label=\"User\", color=\"skyblue\")\n",
    "\n",
    "    # Add favorite restaurants and cuisines\n",
    "    user = agent.knowledge_graph.get_user(user_id)\n",
    "    if user:\n",
    "        for cuisine in user.preferred_cuisines:\n",
    "            G.add_node(cuisine, label=\"Cuisine\", color=\"orange\")\n",
    "            G.add_edge(user_id, cuisine, label=\"likes cuisine\")\n",
    "        \n",
    "        for rest in user.favorite_restaurants:\n",
    "            G.add_node(rest, label=\"Restaurant\", color=\"lightgreen\")\n",
    "            G.add_edge(user_id, rest, label=\"likes restaurant\")\n",
    "\n",
    "    # Add past orders\n",
    "    for order_id, order in agent.knowledge_graph.orders.items():\n",
    "        G.add_node(order_id, label=\"Order\", color=\"gray\")\n",
    "        G.add_edge(user_id, order_id, label=\"placed\")\n",
    "\n",
    "        G.add_node(order[\"restaurant\"], label=\"Restaurant\", color=\"lightgreen\")\n",
    "        G.add_edge(order_id, order[\"restaurant\"], label=\"from\")\n",
    "\n",
    "        for item in order[\"items\"]:\n",
    "            item_name = item[\"name\"]\n",
    "            G.add_node(item_name, label=\"Dish\", color=\"pink\")\n",
    "            G.add_edge(order_id, item_name, label=f\"{item['quantity']}x\")\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    node_colors = [G.nodes[n].get(\"color\", \"white\") for n in G.nodes()]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, node_size=1000, font_size=8)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): d[\"label\"] for u, v, d in G.edges(data=True)})\n",
    "\n",
    "    # Save to image\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    return Image.open(buf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627996fa-0a98-4c7e-b1cb-490cb70606cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chatbot_interface():\n",
    "    agent = FoodOrderingAgent()\n",
    "    \n",
    "    def chat_fn(message, history):\n",
    "        if not message.strip():\n",
    "            return history, \"\"\n",
    "        response = agent.process_message(message)\n",
    "        history.append((message, response))\n",
    "        return history, \"\"\n",
    "    \n",
    "    def reset_fn():\n",
    "        agent.reset_conversation()\n",
    "        return [], \"\"\n",
    "\n",
    "    def show_kg_fn():\n",
    "        img = render_knowledge_graph(agent)\n",
    "        return img\n",
    "    \n",
    "    with gr.Blocks(title=\"Food Ordering Chatbot\", theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\"# 🍕 Food Ordering Chatbot\")\n",
    "        gr.Markdown(\"Welcome to our AI-powered food ordering service! I'll help you find restaurants and place orders.\")\n",
    "\n",
    "        chatbot = gr.Chatbot(value=[], height=500, show_label=False, show_copy_button=True)\n",
    "        \n",
    "        with gr.Row():\n",
    "            msg = gr.Textbox(placeholder=\"Type your message here...\", scale=4, show_label=False, container=False)\n",
    "            send_btn = gr.Button(\"Send\", scale=1, variant=\"primary\")\n",
    "            clear_btn = gr.Button(\"New Order\", scale=1, variant=\"secondary\")\n",
    "\n",
    "        # Knowledge Graph button and viewer\n",
    "        with gr.Row():\n",
    "            show_kg_btn = gr.Button(\"Show Knowledge Graph\", variant=\"secondary\")\n",
    "            kg_image = gr.Image(type=\"pil\", label=\"Knowledge Graph\")\n",
    "\n",
    "        # Event handlers\n",
    "        msg.submit(chat_fn, inputs=[msg, chatbot], outputs=[chatbot, msg])\n",
    "        send_btn.click(chat_fn, inputs=[msg, chatbot], outputs=[chatbot, msg])\n",
    "        clear_btn.click(reset_fn, outputs=[chatbot, msg])\n",
    "        show_kg_btn.click(show_kg_fn, outputs=kg_image)\n",
    "\n",
    "        # Instructions\n",
    "        gr.Markdown(\"\"\"\n",
    "        ### How to use:\n",
    "        1. **Start** by saying hi  \n",
    "        2. **Share** your location - I live in Koramangala Bengaluru  \n",
    "        3. **Tell me** what type of food you want - pizza \n",
    "        4. **Choose** from recommended restaurants - Pizza hut  \n",
    "        5. **Add items** to your cart (e.g., \"Add 2 Margherita Pizza\") / you also have the option to delete item / show cart  \n",
    "        6. **Say 'checkout'** when ready to place order  \n",
    "        7. **Confirm** your order  \n",
    "        8. **Click 'Show Knowledge Graph'** to visualize your preferences and orders  \n",
    "        \"\"\")\n",
    "    \n",
    "    return demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "751c7037-03d7-4e69-ba32-39781a77ab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/xszffxyj0qs0_dvq9dpxskqs7gq7xs/T/ipykernel_44958/3530282059.py:61: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferWindowMemory(\n",
      "/var/folders/sv/xszffxyj0qs0_dvq9dpxskqs7gq7xs/T/ipykernel_44958/3511282784.py:23: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(value=[], height=500, show_label=False, show_copy_button=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "Could not create share link. Missing file: /Users/shettyra/.cache/huggingface/gradio/frpc/frpc_darwin_arm64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.3\n",
      "3. Move the file to this location: /Users/shettyra/.cache/huggingface/gradio/frpc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chianti pizza\n",
      "LLM Extracted Cart JSON: content='I\\'d be happy to help you with that. Here\\'s the JSON output for the given user message:\\n\\n```\\n[\\n  {\\n    \"item\": \"Focaccia Bruschetta\",\\n    \"quantity\": 2\\n  },\\n  {\\n    \"item\": \"Tiramisu\",\\n    \"quantity\": 5\\n  },\\n  {\\n    \"item\": \"Margherita Pizza\",\\n    \"quantity\": 1\\n  }\\n]\\n```\\n\\nLet me know if you have any further questions or if there\\'s anything else I can help you with!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 405, 'total_tokens': 519, 'completion_time': 0.253223712, 'prompt_time': 0.048649806, 'queue_time': 0.267999453, 'total_time': 0.301873518}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None} id='run--32563e39-cf5e-422b-8f97-ab61d8a7122f-0' usage_metadata={'input_tokens': 405, 'output_tokens': 114, 'total_tokens': 519}\n",
      "extracted_items [{'item': 'Focaccia Bruschetta', 'quantity': 2}, {'item': 'Tiramisu', 'quantity': 5}, {'item': 'Margherita Pizza', 'quantity': 1}]\n",
      "Parsed Menu Items: ['Focaccia Bruschetta', 'Margherita Pizza', 'Italian Sausage Pizza', 'Quattro Formaggi Pizza', 'Tuscan Delight', 'Tiramisu']\n",
      "menu items, menu look up [MenuItem(name='Focaccia Bruschetta', price=6.99, description='Fresh tomatoes, basil, and mozzarella on toasted focaccia, drizzled with extra virgin olive oil.', category='Appetizer'), MenuItem(name='Margherita Pizza', price=14.99, description='Classic tomato, mozzarella, and basil on sourdough crust.', category='Main Course'), MenuItem(name='Italian Sausage Pizza', price=16.99, description='Spicy Italian sausage, caramelized onions, and mozzarella on a garlic-infused crust.', category='Main Course'), MenuItem(name='Quattro Formaggi Pizza', price=18.99, description='Four artisanal cheeses - mozzarella, parmesan, gorgonzola, and ricotta - on a crispy crust.', category='Main Course'), MenuItem(name='Tuscan Delight', price=19.99, description='Prosciutto, arugula, and mozzarella on a balsamic glaze-infused crust.', category='Main Course'), MenuItem(name='Tiramisu', price=7.99, description='Ladyfingers soaked in espresso and liqueur, layered with mascarpone cream.', category='Dessert')] {'focaccia bruschetta': MenuItem(name='Focaccia Bruschetta', price=6.99, description='Fresh tomatoes, basil, and mozzarella on toasted focaccia, drizzled with extra virgin olive oil.', category='Appetizer'), 'margherita pizza': MenuItem(name='Margherita Pizza', price=14.99, description='Classic tomato, mozzarella, and basil on sourdough crust.', category='Main Course'), 'italian sausage pizza': MenuItem(name='Italian Sausage Pizza', price=16.99, description='Spicy Italian sausage, caramelized onions, and mozzarella on a garlic-infused crust.', category='Main Course'), 'quattro formaggi pizza': MenuItem(name='Quattro Formaggi Pizza', price=18.99, description='Four artisanal cheeses - mozzarella, parmesan, gorgonzola, and ricotta - on a crispy crust.', category='Main Course'), 'tuscan delight': MenuItem(name='Tuscan Delight', price=19.99, description='Prosciutto, arugula, and mozzarella on a balsamic glaze-infused crust.', category='Main Course'), 'tiramisu': MenuItem(name='Tiramisu', price=7.99, description='Ladyfingers soaked in espresso and liqueur, layered with mascarpone cream.', category='Dessert')}\n",
      "User requested item: Focaccia Bruschetta — matched to: Focaccia Bruschetta\n",
      "User requested item: Tiramisu — matched to: Tiramisu\n",
      "User requested item: Margherita Pizza — matched to: Margherita Pizza\n",
      "LLM Extracted Cart JSON: content='I\\'m ready to help! Based on the user message \"add one tiramisu\", I can extract the following JSON output:\\n\\n```\\n[\\n  {\\n    \"item\": \"Tiramisu\",\\n    \"quantity\": 1\\n  }\\n]\\n```\\n\\nLet me know if you have any more user messages you\\'d like me to process!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 386, 'total_tokens': 456, 'completion_time': 0.08775142, 'prompt_time': 0.04388119, 'queue_time': 0.27276359699999997, 'total_time': 0.13163261}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8b7c3a83f7', 'finish_reason': 'stop', 'logprobs': None} id='run--af5c09d5-e4eb-43ef-a27e-3174e7895a4d-0' usage_metadata={'input_tokens': 386, 'output_tokens': 70, 'total_tokens': 456}\n",
      "extracted_items [{'item': 'Tiramisu', 'quantity': 1}]\n",
      "Parsed Menu Items: ['Focaccia Bruschetta', 'Margherita Pizza', 'Italian Sausage Pizza', 'Quattro Formaggi Pizza', 'Tuscan Delight', 'Tiramisu']\n",
      "menu items, menu look up [MenuItem(name='Focaccia Bruschetta', price=6.99, description='Fresh tomatoes, basil, and mozzarella on toasted focaccia, drizzled with extra virgin olive oil.', category='Appetizer'), MenuItem(name='Margherita Pizza', price=14.99, description='Classic tomato, mozzarella, and basil on sourdough crust.', category='Main Course'), MenuItem(name='Italian Sausage Pizza', price=16.99, description='Spicy Italian sausage, caramelized onions, and mozzarella on a garlic-infused crust.', category='Main Course'), MenuItem(name='Quattro Formaggi Pizza', price=18.99, description='Four artisanal cheeses - mozzarella, parmesan, gorgonzola, and ricotta - on a crispy crust.', category='Main Course'), MenuItem(name='Tuscan Delight', price=19.99, description='Prosciutto, arugula, and mozzarella on a balsamic glaze-infused crust.', category='Main Course'), MenuItem(name='Tiramisu', price=7.99, description='Ladyfingers soaked in espresso and liqueur, layered with mascarpone cream.', category='Dessert')] {'focaccia bruschetta': MenuItem(name='Focaccia Bruschetta', price=6.99, description='Fresh tomatoes, basil, and mozzarella on toasted focaccia, drizzled with extra virgin olive oil.', category='Appetizer'), 'margherita pizza': MenuItem(name='Margherita Pizza', price=14.99, description='Classic tomato, mozzarella, and basil on sourdough crust.', category='Main Course'), 'italian sausage pizza': MenuItem(name='Italian Sausage Pizza', price=16.99, description='Spicy Italian sausage, caramelized onions, and mozzarella on a garlic-infused crust.', category='Main Course'), 'quattro formaggi pizza': MenuItem(name='Quattro Formaggi Pizza', price=18.99, description='Four artisanal cheeses - mozzarella, parmesan, gorgonzola, and ricotta - on a crispy crust.', category='Main Course'), 'tuscan delight': MenuItem(name='Tuscan Delight', price=19.99, description='Prosciutto, arugula, and mozzarella on a balsamic glaze-infused crust.', category='Main Course'), 'tiramisu': MenuItem(name='Tiramisu', price=7.99, description='Ladyfingers soaked in espresso and liqueur, layered with mascarpone cream.', category='Dessert')}\n",
      "User requested item: Tiramisu — matched to: Tiramisu\n",
      "LLM Extracted Cart JSON: content='I\\'d be happy to help you with that!\\n\\nGiven the user message \"add 1 Tuscan Delight\", I can extract the following information:\\n\\n* Dish name: Tuscan Delight\\n* Quantity: 1\\n\\nHere\\'s the JSON output:\\n```\\n[\\n  {\\n    \"item\": \"Tuscan Delight\",\\n    \"quantity\": 1\\n  }\\n]\\n```\\nLet me know if you have any more user messages you\\'d like me to process!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 388, 'total_tokens': 485, 'completion_time': 0.068012288, 'prompt_time': 0.043252313, 'queue_time': 0.274693646, 'total_time': 0.111264601}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_2717d04279', 'finish_reason': 'stop', 'logprobs': None} id='run--1220ced7-7b9b-40a3-98f7-626a92cb2356-0' usage_metadata={'input_tokens': 388, 'output_tokens': 97, 'total_tokens': 485}\n",
      "extracted_items [{'item': 'Tuscan Delight', 'quantity': 1}]\n",
      "Parsed Menu Items: ['Focaccia Bruschetta', 'Margherita Pizza', 'Italian Sausage Pizza', 'Quattro Formaggi Pizza', 'Tuscan Delight', 'Tiramisu']\n",
      "menu items, menu look up [MenuItem(name='Focaccia Bruschetta', price=6.99, description='Fresh tomatoes, basil, and mozzarella on toasted focaccia, drizzled with extra virgin olive oil.', category='Appetizer'), MenuItem(name='Margherita Pizza', price=14.99, description='Classic tomato, mozzarella, and basil on sourdough crust.', category='Main Course'), MenuItem(name='Italian Sausage Pizza', price=16.99, description='Spicy Italian sausage, caramelized onions, and mozzarella on a garlic-infused crust.', category='Main Course'), MenuItem(name='Quattro Formaggi Pizza', price=18.99, description='Four artisanal cheeses - mozzarella, parmesan, gorgonzola, and ricotta - on a crispy crust.', category='Main Course'), MenuItem(name='Tuscan Delight', price=19.99, description='Prosciutto, arugula, and mozzarella on a balsamic glaze-infused crust.', category='Main Course'), MenuItem(name='Tiramisu', price=7.99, description='Ladyfingers soaked in espresso and liqueur, layered with mascarpone cream.', category='Dessert')] {'focaccia bruschetta': MenuItem(name='Focaccia Bruschetta', price=6.99, description='Fresh tomatoes, basil, and mozzarella on toasted focaccia, drizzled with extra virgin olive oil.', category='Appetizer'), 'margherita pizza': MenuItem(name='Margherita Pizza', price=14.99, description='Classic tomato, mozzarella, and basil on sourdough crust.', category='Main Course'), 'italian sausage pizza': MenuItem(name='Italian Sausage Pizza', price=16.99, description='Spicy Italian sausage, caramelized onions, and mozzarella on a garlic-infused crust.', category='Main Course'), 'quattro formaggi pizza': MenuItem(name='Quattro Formaggi Pizza', price=18.99, description='Four artisanal cheeses - mozzarella, parmesan, gorgonzola, and ricotta - on a crispy crust.', category='Main Course'), 'tuscan delight': MenuItem(name='Tuscan Delight', price=19.99, description='Prosciutto, arugula, and mozzarella on a balsamic glaze-infused crust.', category='Main Course'), 'tiramisu': MenuItem(name='Tiramisu', price=7.99, description='Ladyfingers soaked in espresso and liqueur, layered with mascarpone cream.', category='Dessert')}\n",
      "User requested item: Tuscan Delight — matched to: Tuscan Delight\n",
      "No matching item found in cart for: delete\n",
      "No matching item found in cart for: 1\n",
      "✅ Order added to Knowledge Graph: ORD20250707205740\n",
      "\n",
      "=== KNOWLEDGE GRAPH STATE ===\n",
      "📌 Users:\n",
      "{}\n",
      "\n",
      "📌 Restaurants:\n",
      "{}\n",
      "\n",
      "📌 Orders:\n",
      "{'ORD20250707205740': {'items': [{'name': 'Focaccia Bruschetta',\n",
      "                                  'price': 6.99,\n",
      "                                  'quantity': 2},\n",
      "                                 {'name': 'Tiramisu',\n",
      "                                  'price': 7.99,\n",
      "                                  'quantity': 4},\n",
      "                                 {'name': 'Margherita Pizza',\n",
      "                                  'price': 14.99,\n",
      "                                  'quantity': 1},\n",
      "                                 {'name': 'Tiramisu',\n",
      "                                  'price': 7.99,\n",
      "                                  'quantity': 1},\n",
      "                                 {'name': 'Tuscan Delight',\n",
      "                                  'price': 19.99,\n",
      "                                  'quantity': 1}],\n",
      "                       'location': 'Koramangala, Bengaluru, India',\n",
      "                       'order_id': 'ORD20250707205740',\n",
      "                       'restaurant': 'Chianti, Koramangala',\n",
      "                       'timestamp': '2025-07-07T20:57:40.540931',\n",
      "                       'total': 88.91,\n",
      "                       'user_id': 'user_001'}}\n",
      "=============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "def view_knowledge_graph():\n",
    "    \n",
    "    state = {\n",
    "        \"Users\": agent.knowledge_graph.users,\n",
    "        \"Orders\": agent.knowledge_graph.orders,\n",
    "        \"Restaurants\": agent.knowledge_graph.restaurants\n",
    "    }\n",
    "    return json.dumps(state, indent=2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set up environment variables (you'll need to set these)\n",
    "    if not GROQ_API_KEY:\n",
    "        print(\"⚠️  Please set GROQ_API_KEY environment variable\")\n",
    "        print(\"   export GROQ_API_KEY='your_groq_api_key_here'\")\n",
    "    \n",
    "    # Create and launch interface\n",
    "    demo = create_chatbot_interface()\n",
    "    demo.launch(\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7861,\n",
    "        share=True  # Set to False for local only\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f2f648-ff6d-44e2-b848-f6089376654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb6dde9-f675-4ffa-ad39-eebf93afb2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://shettyra:****@rt.artifactory.tio.systems/artifactory/api/pypi/pypi-dp-caps-local/simple\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://rt.artifactory.tio.systems/artifactory/api/pypi/pypi-dp-caps-local/simple/pipreqs/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pipreqs\n",
      "  Downloading pipreqs-0.5.0-py3-none-any.whl (33 kB)\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://rt.artifactory.tio.systems/artifactory/api/pypi/pypi-dp-caps-local/simple/docopt/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting docopt==0.6.2 (from pipreqs)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://rt.artifactory.tio.systems/artifactory/api/pypi/pypi-dp-caps-local/simple/ipython/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25hCollecting ipython==8.12.3 (from pipreqs)\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.3/798.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nbconvert<8.0.0,>=7.11.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from pipreqs) (7.16.6)\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://rt.artifactory.tio.systems/artifactory/api/pypi/pypi-dp-caps-local/simple/yarg/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting yarg==0.1.9 (from pipreqs)\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://rt.artifactory.tio.systems/artifactory/api/pypi/pypi-dp-caps-local/simple/backcall/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting backcall (from ipython==8.12.3->pipreqs)\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: decorator in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.1.7)\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://rt.artifactory.tio.systems/artifactory/api/pypi/pypi-dp-caps-local/simple/pickleshare/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pickleshare (from ipython==8.12.3->pipreqs)\n",
      "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (2.19.2)\n",
      "Requirement already satisfied: stack-data in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (4.9.0)\n",
      "Requirement already satisfied: appnope in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.1.4)\n",
      "Requirement already satisfied: requests in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from yarg==0.1.9->pipreqs) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.13.4)\n",
      "Requirement already satisfied: bleach[css]!=5.0.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (5.8.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (5.10.4)\n",
      "Requirement already satisfied: packaging in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (24.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jedi>=0.16->ipython==8.12.3->pipreqs) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (4.3.8)\n",
      "Requirement already satisfied: typing-extensions in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from mistune<4,>=2.0.3->nbconvert<8.0.0,>=7.11.0->pipreqs) (4.14.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (8.6.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (4.24.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from pexpect>4.3->ipython==8.12.3->pipreqs) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.12.3->pipreqs) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from beautifulsoup4->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from requests->yarg==0.1.9->pipreqs) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from requests->yarg==0.1.9->pipreqs) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from requests->yarg==0.1.9->pipreqs) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from requests->yarg==0.1.9->pipreqs) (2025.6.15)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from stack-data->ipython==8.12.3->pipreqs) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from stack-data->ipython==8.12.3->pipreqs) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from stack-data->ipython==8.12.3->pipreqs) (0.2.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (6.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shettyra/Library/Caches/pypoetry/virtualenvs/raise-hackathon-prosus-track-bnXj1eug-py3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.17.0)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13783 sha256=ebb49455ad55f874657513f156f229d50bc0ee6a16e6a3cd813b2b127da8b8b5\n",
      "  Stored in directory: /Users/shettyra/Library/Caches/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built docopt\n",
      "Installing collected packages: pickleshare, docopt, backcall, yarg, ipython, pipreqs\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.37.0\n",
      "    Uninstalling ipython-8.37.0:\n",
      "      Successfully uninstalled ipython-8.37.0\n",
      "Successfully installed backcall-0.2.0 docopt-0.6.2 ipython-8.12.3 pickleshare-0.7.5 pipreqs-0.5.0 yarg-0.1.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pipreqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3351a5c6-3332-4b94-b20a-068b5b58a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Not scanning for jupyter notebooks.\n",
      "INFO: Successfully saved requirements file in ./requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!pipreqs . --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1a0663-feb3-45a2-b87f-4999407b3c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Untitled1.ipynb to script\n",
      "[NbConvertApp] Writing 40765 bytes to Untitled1.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script Untitled1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbfd0b4f-cd9c-4691-959f-bcab525785ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Not scanning for jupyter notebooks.\n",
      "WARNING: Import named \"gradio\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"gradio\" was resolved to \"gradio:5.35.0\" package (https://pypi.org/project/gradio/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"groq\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"groq\" was resolved to \"groq:0.29.0\" package (https://pypi.org/project/groq/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"httpx\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"httpx\" was resolved to \"httpx:0.28.1\" package (https://pypi.org/project/httpx/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"langchain\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"langchain\" was resolved to \"langchain:0.3.26\" package (https://pypi.org/project/langchain/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"langchain_groq\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"langchain_groq\" was resolved to \"langchain-groq:0.3.5\" package (https://pypi.org/project/langchain-groq/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"matplotlib\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"matplotlib\" was resolved to \"matplotlib:3.10.3\" package (https://pypi.org/project/matplotlib/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"Pillow\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"Pillow\" was resolved to \"pillow:11.3.0\" package (https://pypi.org/project/pillow/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"pydantic\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"pydantic\" was resolved to \"pydantic:2.11.7\" package (https://pypi.org/project/pydantic/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"Requests\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"Requests\" was resolved to \"requests:2.32.4\" package (https://pypi.org/project/requests/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "INFO: Successfully saved requirements file in ./requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!pipreqs . --force\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc691a-d1e0-4adb-a0e0-ad7745c542a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
